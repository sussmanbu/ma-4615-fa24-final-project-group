[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "This comes from the file data.qmd.\nYour first steps in this project will be to find data to work on.\nI recommend trying to find data that interests you and that you are knowledgeable about. A bad example would be if you have no interest in video games but your data set is about video games. I also recommend finding data that is related to current events, social justice, and other areas that have an impact.\nInitially, you will study one dataset but later you will need to combine that data with another dataset. For this reason, I recommend finding data that has some date and/or location components. These types of data are conducive to interesting visualizations and analysis and you can also combine this data with other data that also has a date or location variable. Data from the census, weather data, economic data, are all relatively easy to combine with other data with time/location components."
  },
  {
    "objectID": "data.html#what-makes-a-good-data-set",
    "href": "data.html#what-makes-a-good-data-set",
    "title": "Data",
    "section": "What makes a good data set?",
    "text": "What makes a good data set?\n\nData you are interested in and care about.\nData where there are a lot of potential questions that you can explore.\nA data set that isn’t completely cleaned already.\nMultiple sources for data that you can combine.\nSome type of time and/or location component."
  },
  {
    "objectID": "data.html#where-to-keep-data",
    "href": "data.html#where-to-keep-data",
    "title": "Data",
    "section": "Where to keep data?",
    "text": "Where to keep data?\nBelow 50mb: In dataset folder\nAbove 50mb: In dataset_ignore folder. This folder will be ignored by git so you’ll have to manually sync these files across your team.\n\nSharing your data\nFor small datasets (&lt;50mb), you can use the dataset folder that is tracked by github. Add the files just like you would any other file.\nIf you create a folder named data this will cause problems.\nFor larger datasets, you’ll need to create a new folder in the project root directory named dataset-ignore. This will be ignored by git (based off the .gitignore file in the project root directory) which will help you avoid issues with Github’s size limits. Your team will have to manually make sure the data files in dataset-ignore are synced across team members.\nYour load_and_clean_data.R file is how you will load and clean your data. Here is a an example of a very simple one.\n\nsource(\n  \"scripts/load_and_clean_data.R\",\n  echo = TRUE # Use echo=FALSE or omit it to avoid code output  \n)\n\n\n&gt; library(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n&gt; loan_data &lt;- read_csv(here::here(\"dataset\", \"loan_refusal.csv\"))\n\n\nRows: 20 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): bank\ndbl (4): min, white, himin, hiwhite\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n&gt; loan_data_clean &lt;- pivot_longer(loan_data, 2:5, names_to = \"group\", \n+     values_to = \"refusal_rate\")\n\n&gt; write_rds(loan_data_clean, file = here::here(\"dataset\", \n+     \"loan_refusal_clean.rds\"))\n\n\nYou should never use absolute paths (eg. /Users/danielsussman/path/to/project/ or C:\\MA415\\\\Final_Project\\).\nYou might consider using the here function from the here package to avoid path problems.\n\n\nLoad and clean data script\nThe idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them. This file might create a derivative data set that you then use for your subsequent analysis. Note that you don’t need to run this script from every post/page. Instead, you can load in the results of this script, which could be plain text files or .RData files. In your data page you’ll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes. To link to this file, you can use [cleaning script](/scripts/load_and_clean_data.R) wich appears as cleaning script."
  },
  {
    "objectID": "data.html#rubric-on-this-page",
    "href": "data.html#rubric-on-this-page",
    "title": "Data",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nDescribe where/how to find data.\n\nYou must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\nWhy was the data collected/curated? Who put it together? (This is important, if you don’t know why it was collected then that might not be a good dataset to look at.\n\nDescribe the different data files used and what each variable means.\n\nIf you have many variables then only describe the most relevant ones and summarize the rest.\n\nDescribe any cleaning you had to do for your data.\n\nYou must include a link to your load_and_clean_data.R file.\nRrename variables and recode factors to make data more clear.\nAlso, describe any additional R packages you used outside of those covered in class.\nDescribe and show code for how you combined multiple data files and any cleaning that was necessary for that.\nSome repetition of what you do in your load_and_clean_data.R file is fine and encouraged if it helps explain what you did.\n\nOrganization, clarity, cleanliness of the page\n\nMake sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\nThis page should be self-contained."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "analysis.html#note-on-attribution",
    "href": "analysis.html#note-on-attribution",
    "title": "Analysis",
    "section": "Note on Attribution",
    "text": "Note on Attribution\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don’t have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don’t need a formal citation.\nIf you are directly quoting from a source, please make that clear. You can show quotes using &gt; like this\n&gt; To be or not to be.\n\nTo be or not to be."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 7, 2024 at 11:59pm.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 3\n\n\nPhase 1 of the EDA\n\n\n\nBlog Post 3\n\n\n\nData Link: https://www.kaggle.com/datasets/konradb/prison-population-in-the-us?select=populations_states.csv \n\n\n\n\n\nOct 23, 2024\n\n\nGroup 10\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 2\n\n\nProgress Discussion and Dataset Investigating\n\n\n\nBlog Post 2\n\n\n\nData Link: https://www.kaggle.com/datasets/konradb/prison-population-in-the-us?select=populations_states.csv \n\n\n\n\n\nOct 18, 2024\n\n\nGroup 10\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 1\n\n\nThree Initial Datasets are chosen\n\n\n\nBlog Post 1\n\n\n\n\n\n\n\n\n\nOct 9, 2024\n\n\nGroup_10\n\n\n\n\n\n\n\n\n\n\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post. \n\n\n\n\n\nFeb 23, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting. \n\n\n\n\n\nFeb 21, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (For your first blog post, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext time, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2024-10-09-blog-post-1/blog-post-1.html",
    "href": "posts/2024-10-09-blog-post-1/blog-post-1.html",
    "title": "Blog Post 1",
    "section": "",
    "text": "Dataset 1 - “Police Killings US”\nDataset Link: https://www.kaggle.com/datasets/azizozmen/police-killings-us\nRows and Columns: 2535 rows and 14 columns of data detailing police-related killings in the U.S.\nThe dataset collects information on police killings, including demographic and situational factors like race, threat level, and mental illness, aiming to highlight trends and disparities. The data loaded successfully, though some columns like race and flee have missing values that need to be cleaned for accurate analysis. We can focus on exploring racial disparities, such as whether certain racial groups are disproportionately killed by police, and how factors like threat level or body camera usage vary by race. The main challenges include handling missing data and ensuring that the analysis of racial disparities is unbiased and supported by complete data.\n\n\nDataset 2 - “WHO Suicide Statistics”\nDataset Link: https://www.kaggle.com/datasets/szamil/who-suicide-statistics\nRows: great quantities Columns: 6\nWe would like to analyze how suicide rates vary by race across different countries or regions. We can also analyze the trends in suicide rates over time for different racial groups to see how rates have evolved. What challenges do you foresee?\nThe dataset is not separated by race, but nationality, which would make it more difficult to address racial disparities among suicidal rates. There are limited columns, which can reduce the potential for interaction between various variables. Dealing with such a heavy subject, we would not want to oversimplify the complex phenomena. It doesn’t have any insight about the suicide risk factors, which we would be eager to analyze.\n\n\nDataset 3 - “New York City Leading Causes of Death”\nDataset Link: https://catalog.data.gov/dataset/new-york-city-leading-causes-of-death/resource/845a3736-6ce4-46da-a82d-8a5f9add81f1\nNew York City’s health data is represented in a dataset showing the leading causes of death by sex and ethnicity since 2007. This resource, created from NYC death certificates, provides information on mortality trends with 2103 observations across several important variables. The data includes year, leading cause, sex, race, death count, and death rates, allowing for analysis of public health patterns in New York City. This dataset offers a chance to study important health trends, but it has limitations. The small number of columns may restrict the depth of analysis possible, and dealing with empty fields is another limitation to consider. Despite these issues, the data provides useful information about how different demographic groups are affected by various health problems over time. By studying this data, we aim to find patterns in death rates across different populations and identify potential areas where public health efforts could be focused."
  },
  {
    "objectID": "posts/2024-10-23-blog-post-3/blog_post3.html",
    "href": "posts/2024-10-23-blog-post-3/blog_post3.html",
    "title": "Blog Post 3",
    "section": "",
    "text": "We are continuing to closely examine the admissions and releases dataset. The article highlights significant differences in admission and release patterns across racial groups and states, especially during the pandemic. It found that, although overall prison admissions decreased, Black and Latino populations were affected more by admissions and slower release rates than white populations. While some data from before the pandemic (pre-2019) is included, we chose to focus on data from 2019 to 2022. We also noticed that data is available for only some states, limiting our view of the whole U.S., so we plan to focus on a few specific states. The article explains that this is because states had different policies for releases and for reporting (such as self-reporting versus staff assignments).\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\ndata = readRDS(\"dataset/cleaned_dataset.rds\")\nhead(data)\n\n        Date Total_Admissions White_Admissions Black_Admissions\n1 2015-02-01             1583              600              193\n2 2015-03-01             1580              615              189\n3 2015-04-01             1779              706              235\n4 2015-05-01             1821              730              260\n5 2015-06-01             1689              704              215\n6 2015-07-01             1871              758              223\n  Hispanic_Admissions AmericanIndian_Admissions Asian_Admissions\n1                 633                       130                6\n2                 640                       114                3\n3                 701                       115                4\n4                 669                       125                8\n5                 618                       129                0\n6                 738                       121                5\n  Other_Admissions Total_Releases White_Releases Black_Releases\n1               21           1649            653            194\n2               19           1559            644            169\n3               18           1693            703            206\n4               29           1659            685            193\n5               23           1570            651            174\n6               26           1718            673            224\n  Hispanic_Releases AmericanIndian_Releases Asian_Releases Other_Releases\n1               688                      85              7             22\n2               610                     111              6             19\n3               657                      93              5             29\n4               616                     136              3             26\n5               603                     111              7             24\n6               662                     132              5             22\n    State\n1 Arizona\n2 Arizona\n3 Arizona\n4 Arizona\n5 Arizona\n6 Arizona\n\n\n\ndata$date &lt;- as.Date(data$Date)\ndata_filtered = data %&gt;%\n  filter(date &gt;= as.Date(\"2019-01-01\") & date &lt;= as.Date(\"2022-01-01\")) %&gt;%\n  group_by(date) %&gt;%\n  summarise(\n    Total_Admissions = sum(Total_Admissions, na.rm = TRUE),\n    Total_Releases = sum(Total_Releases, na.rm = TRUE)\n  )\n\nggplot(data_filtered, aes(x = date)) +\n  geom_line(aes(y = Total_Admissions, color = \"Total Admissions\")) +\n  geom_line(aes(y = Total_Releases, color = \"Total Releases\")) +\n  labs(\n    title = \"Total Prison Admissions and Releases for 18 States (2019-2022)\",\n    x = \"Date\",\n    y = \"Count\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(\n    values = c(\"Total Admissions\" = \"blue\", \"Total Releases\" = \"red\"),\n    name = NULL \n  ) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5), \n    axis.title.x = element_text(size = 13, margin = margin(t = 10)), \n    axis.title.y = element_text(size = 13, margin = margin(r = 10)),  \n    axis.text.x = element_text(size = 11.2), \n    axis.text.y = element_text(size = 12), \n    legend.position = \"bottom\",\n    legend.text = element_text(size = 12), \n    legend.key.size = unit(1.2, \"cm\") \n  ) +\n  scale_x_date(\n    date_breaks = \"4 months\",  \n    date_labels = \"%b %Y\"      \n  )\n\n\n\n\n\n\n\n\nThe plot titled “Total Prison Admissions and Releases for 18 States (2019-2022)” provides insights into the trends of total prison admissions and releases during this period, with the blue line representing admissions and the red line indicating releases.\nThe data captures patterns before, during, and after the COVID-19 pandemic. Notably, there is a significant decline in admissions from February to April 2020, with counts dropping from 17500 to just below 5000, coinciding with the early rise of the pandemic. Additionally, two spikes in releases are observed: one in April 2020, possibly related to prison population management, and another in July 2020.\nThe subsequent rise in admissions during September 2020, followed by a decline until November, suggests evolving responses within the correctional system.\nWhile this analysis highlights distinct patterns, it is essential to consider potential factors behind these trends. For instance, the lockdown may have contributed to reduced crime rates due to fewer people being outside, leading to fewer arrests. Additionally, individuals with minor offenses might have been released earlier to manage the pandemic’s impact on prison populations. However, these interpretations are hypotheses that require further investigation and reading to confirm their validity.\nThis analysis underscores the complexity of interpreting shifts in prison data during unprecedented events like the COVID-19 pandemic.\n\ndata_filtered &lt;- data |&gt; \n  filter(Date &gt;= as.Date(\"2019-01-01\") & Date &lt;= as.Date(\"2022-01-01\")) |&gt; \n  group_by(date) |&gt; \n  summarize(\n    White_Admissions = sum(White_Admissions, na.rm = TRUE),\n    White_Releases = sum(White_Releases, na.rm = TRUE)\n  )\n \ndata_filtered |&gt; \n  ggplot(aes(x = date)) +\n  geom_line(aes(y = White_Admissions, color = \"White admissions\"), linewidth = 0.5) +\n  geom_line(aes(y = White_Releases, color = \"White releases\"), linewidth = 0.5) +\n  scale_color_manual(values = c(\"White admissions\" = \"blue\", \"White releases\" = \"red\")) +\n  scale_x_date(\n    date_breaks = \"4 months\",\n    date_labels = \"%b %Y\"\n  ) +\n  labs(\n    title = \"Total White Admissions and Releases for 18 States (2019-2022)\",\n    x = \"Date\",\n    y = \"White Admissions and Releases\",\n    color = \"\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n    axis.title.x = element_text(size = 13, margin = margin(t = 10)),\n    axis.title.y = element_text(size = 13, margin = margin(r = 10)),\n    axis.text.x = element_text(size = 11.2),\n    axis.text.y = element_text(size = 12),\n    legend.text = element_text(size = 12),\n    legend.key.size = unit(1.2, \"cm\") \n  )\n\n\n\n\n\n\n\n\nIn the white population plot, there is a steady trend in admissions and releases. Until March 2020, there is a spike in releases while there is a decrease in admissions. Then, as the admission slowly increases and the releases decrease, there occurs a small spike and decrease again in releases and admissions. Towards November 2020 and onwards, the relationship between admissions and releases start to regulate but not in the same numbers as in 2019.\n\ndata_filtered &lt;- data |&gt; \n  filter(Date &gt;= as.Date(\"2019-01-01\") & Date &lt;= as.Date(\"2022-01-01\")) |&gt; \n  group_by(date) |&gt; \n  summarize(\n    AmericanIndian_Admissions = sum(AmericanIndian_Admissions, na.rm = TRUE),\n    AmericanIndian_Releases = sum(AmericanIndian_Releases, na.rm = TRUE)\n  )\n \ndata_filtered |&gt; \n  ggplot(aes(x = date)) +\n  geom_line(aes(y = AmericanIndian_Admissions, color = \"American-Indian admissions\")) +\n  geom_line(aes(y = AmericanIndian_Releases, color = \"American-Indian releases\"), size = 0.5) +\n  scale_color_manual(values = c(\"American-Indian admissions\" = \"blue\", \"American-Indian releases\" = \"red\")) +\n  scale_x_date(\n    date_breaks = \"4 months\",\n    date_labels = \"%b %Y\"\n  ) +\n  labs(\n    title = \"Total American-Indian Admissions and Releases for 18 States (2019-2022)\",\n    x = \"Date\",\n    y = \"American-Indian Admissions and Releases\",\n    color = \"\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n    axis.title.x = element_text(size = 13, margin = margin(t = 10)),\n    axis.title.y = element_text(size = 13, margin = margin(r = 10)),\n    axis.text.x = element_text(size = 11.2),\n    axis.text.y = element_text(size = 12),\n    legend.text = element_text(size = 12),\n    legend.key.size = unit(1.2, \"cm\") \n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nThe graph illustrates trends in American-Indian admissions and releases from 2019 to 2022. Before covid period the admissions and releases were fluctuation in the range of 400 and 325 count. In the early part of 2019, admissions and releases were close in number, with some fluctuations. Around March 2020, there is a sharp drop in admissions (from 350 to 175) and a spike in releases (from 350 to 430). Admissions remain lower than releases for most of the period after March 2020, despite some fluctuations. The trend for both admissions and releases appears more volatile from 2021 onward, with admissions and releases converging and diverging frequently. By the end of the chart, both admissions and releases have decreased from their initial 2019 levels, with both metrics reaching similar levels but remaining relatively low.\n\ndata$date &lt;- as.Date(data$Date)\ndata_aggregated &lt;- data %&gt;%\n  group_by(date) %&gt;%\n  summarise(\n    total_black_admissions = sum(Black_Admissions, na.rm = TRUE),\n    total_black_releases = sum(Black_Releases, na.rm = TRUE),\n    .groups = 'drop'\n  )\n\ndata_filtered &lt;- data_aggregated %&gt;%\n  filter(date &gt;= as.Date(\"2019-01-01\") & date &lt;= as.Date(\"2022-01-31\"))\n\nggplot(data_filtered, aes(x = date)) +\n  geom_line(aes(y = total_black_admissions, color = \"Black Admissions\")) +\n  geom_line(aes(y = total_black_releases, color = \"Black Releases\")) +\n  labs(\n    title = \"Total Black Admissions and Releases For 18 States (2019-2022)\",\n    x = \"Date\",\n    y = \"Total Black Admissions and Releases\"\n  ) +\n  scale_x_date(date_breaks = \"4 months\", date_labels = \"%b %Y\") +  \n  theme_minimal() +\n  scale_color_manual(\n    values = c(\"Black Admissions\" = \"blue\", \"Black Releases\" = \"red\"),\n    name = NULL  \n  ) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5), \n    axis.title.x = element_text(size = 13, margin = margin(t = 10)), \n    axis.title.y = element_text(size = 13, margin = margin(r = 10)),  \n    axis.text.x = element_text(size = 11.2), \n    axis.text.y = element_text(size = 12), \n    legend.position = \"bottom\",\n    legend.text = element_text(size = 12), \n    legend.key.size = unit(1.2, \"cm\") \n  )\n\n\n\n\n\n\n\n\nThe graph illustrates trends in Black admissions and releases from 2019 to 2022. Both lines display relative stability in early 2019; however, admissions experience a sharp decline around March 2020, likely due to COVID-19 disruptions. Admissions decreased to around 500 by April 2020, while releases exhibit more fluctuations. Notably, there are two spikes in releases: one in April 2020, possibly related to efforts to manage prison populations during the pandemic, and another in July 2020. Admissions show some recovery, reaching around 3500 by late 2020, but remain significantly lower than pre-pandemic levels\n\ndata_filtered = data %&gt;%\n  filter(date &gt;= as.Date(\"2019-01-01\") & date &lt;= as.Date(\"2022-01-01\")) %&gt;%\n  group_by(date) %&gt;%\n  summarise(\n    Hispanic_Admissions = sum(Hispanic_Admissions, na.rm = TRUE),\n    Hispanic_Releases = sum(Hispanic_Releases, na.rm = TRUE)\n  )\n\nggplot(data_filtered, aes(x = date)) +\n  geom_line(aes(y = Hispanic_Admissions, color = \"Hispanic Admissions\")) +\n  geom_line(aes(y = Hispanic_Releases, color = \"Hispanic Releases\")) +\n  labs(\n    title = \"Total Hispanic Prison Admissions and Releases for 18 States (2019-2022)\",\n    x = \"Date\",\n    y = \"Count\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(\n    values = c(\"Hispanic Admissions\" = \"blue\", \"Hispanic Releases\" = \"red\"),\n    name = NULL  # Remove the legend label\n  ) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5), \n    axis.title.x = element_text(size = 13, margin = margin(t = 10)), \n    axis.title.y = element_text(size = 13, margin = margin(r = 10)),  \n    axis.text.x = element_text(size = 11.2), \n    axis.text.y = element_text(size = 12), \n    legend.position = \"bottom\",\n    legend.text = element_text(size = 12), \n    legend.key.size = unit(1.2, \"cm\") \n  ) +\n  scale_x_date(\n    date_breaks = \"4 months\",  \n    date_labels = \"%b %Y\"      \n  )\n\n\n\n\n\n\n\n\nThe graph illustrates trends in Hispanic admissions and releases from 2019 to 2022. Prior to 2020, both admissions and releases have a relatively steady trend, with releases slightly higher than admissions at times. Around March 2020 (the start of the COVID-19 pandemic), there’s a sharp drop in admissions (from approximately 4200 to less than 1000). There are two spikes in releases shortly after, possibly as a response to the pandemic. After the initial pandemic impact, both admissions and releases fluctuate, but the admissions remain lower than pre-2020 levels. Releases eventually stabilize around mid-2021 but continue to hover close to the admission rates.\n\ndata_filtered = data %&gt;%\n  filter(date &gt;= as.Date(\"2019-01-01\") & date &lt;= as.Date(\"2022-01-01\")) %&gt;%\n  group_by(date) %&gt;%\n  summarise(\n    Asian_Admissions = sum(Asian_Admissions, na.rm = TRUE),\n    Asian_Releases = sum(Asian_Releases, na.rm = TRUE)\n  )\n\nggplot(data_filtered, aes(x = date)) +\n  geom_line(aes(y = Asian_Admissions, color = \"Asian Admissions\")) +\n  geom_line(aes(y = Asian_Releases, color = \"Asian Releases\")) +\n  labs(\n    title = \"Total Asian Prison Admissions and Releases for 18 States (2019-2022)\",\n    x = \"Date\",\n    y = \"Count\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(\n    values = c(\"Asian Admissions\" = \"blue\", \"Asian Releases\" = \"red\"),\n    name = NULL  # Remove the legend label\n  ) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5), \n    axis.title.x = element_text(size = 13, margin = margin(t = 10)), \n    axis.title.y = element_text(size = 13, margin = margin(r = 10)),  \n    axis.text.x = element_text(size = 11.2), \n    axis.text.y = element_text(size = 12), \n    legend.position = \"bottom\",\n    legend.text = element_text(size = 12), \n    legend.key.size = unit(1.2, \"cm\") \n  ) +\n  scale_x_date(\n    date_breaks = \"4 months\",  \n    date_labels = \"%b %Y\"      \n  )\n\n\n\n\n\n\n\n\nThe graph illustrates trends in Asian admissions and releases from 2019 to 2022. This plot shows consistently low and stable numbers from 2019 to 2022, with values generally under 100, which is significantly smaller than other racial groups. The trend remains relatively flat throughout 2019, but there’s a noticeable drop of admissions and a rise of releases slightly passed 100 around early 2020. Following this decline, admissions and releases gradually return to previous levels, hovering around 50 to 70 for most of 2021. The y-axis, capped just above 100, highlights the low representation of the Asian population in prison admissions and releases, suggesting minimal impact on the overall trend compared to other groups.\n\ndata_filtered &lt;- data |&gt; \n  filter(Date &gt;= as.Date(\"2019-01-01\") & Date &lt;= as.Date(\"2022-01-01\")) |&gt; \n  group_by(date) |&gt; \n  summarize(\n    Other_Admissions = sum(Other_Admissions, na.rm = TRUE),\n    Other_Releases = sum(Other_Releases, na.rm = TRUE)\n  )\n \ndata_filtered |&gt; \n  ggplot(aes(x = date)) +\n  geom_line(aes(y = Other_Admissions, color = \"Other admissions\"), size = 0.5) +\n  geom_line(aes(y = Other_Releases, color = \"Other releases\"), size = 0.5) +\n  scale_color_manual(values = c(\"Other admissions\" = \"blue\", \"Other releases\" = \"red\")) +\n  scale_x_date(\n    date_breaks = \"4 months\",\n    date_labels = \"%b %Y\"\n  ) +\n  labs(\n    title = \"Total Other Admissions and Releases for 18 States (2019-2022)\",\n    x = \"Date\",\n    y = \"Other Admissions and Releases\",\n    color = \"\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n    axis.title.x = element_text(size = 13, margin = margin(t = 10)),\n    axis.title.y = element_text(size = 13, margin = margin(r = 10)),\n    axis.text.x = element_text(size = 11.2),\n    axis.text.y = element_text(size = 12),\n    legend.text = element_text(size = 12),\n    legend.key.size = unit(1.2, \"cm\") \n  )\n\n\n\n\n\n\n\n\nThe graph illustrates trends in admissions and releases of other races from 2019 to 2022. Notably, in the pre-COVID period, there is a significant spike in releases from September to November, increasing from 250 to 2000 in just one month and then dropping back to 250. This spike is unrelated to COVID-19. During the COVID-19 period, admissions show a minor decline from February 2020, decreasing from 250 to 100, then rising again. Releases also exhibit a small spike in July 2020. After March 2021, both lines move closer to each other, though they remain slightly lower than pre-pandemic levels.\nMoving forward, we will narrow our analysis to focus on specific states, examining how admissions and releases have varied across racial groups. This targeted approach will help us better understand the differences in trends during the pandemic. By comparing these patterns, we aim to uncover more nuanced insights into racial disparities within the prison system."
  },
  {
    "objectID": "posts/2024-10-18-blog-post-2/blog-post-2.html",
    "href": "posts/2024-10-18-blog-post-2/blog-post-2.html",
    "title": "Blog Post 2",
    "section": "",
    "text": "In response to our first blog post, we shifted our focus to analyzing the US prison population. This dataset includes information on admission and release totals, along with the total broken down by race, the date of this data collection, and the states from which the data was gathered. The data comes from the article titled “COVID-19 Amplified Racial Disparities in the US Criminal Legal System,” collected by a team of researchers. This data was collected to examine how the COVID-19 pandemic affected the racial composition of US prisons. Despite an overall decrease in the prison population, the proportion of incarcerated Black and Latino prisoners increased. So, the study aims to understand why this happened and how the pandemic made racial inequalities in the prison system worse. The data is available on Nature.com, a scientific journal that publishes peer-reviewed research and news.\n\n\nWe firstly found the dataset on Kaggle. There is a link to github(https://github.com/jkbren/incarcerated-populations-data/), which is also the original source of this dataset. Also, there is a nature article discussing about the dataset (link https://www.nature.com/articles/s41586-023-05980-2)).\n\n\nThe question asked most about this dataset is “What are the long-term trends in admissions and releases across different states, and how do these trends correlate with changes in policy”. This is also the concern of policymakers.\n\ndf = read.csv(\"admissions_releases_states.csv\")\nstr(df)\n\n'data.frame':   1914 obs. of  16 variables:\n $ date               : chr  \"2015-02-01\" \"2015-03-01\" \"2015-04-01\" \"2015-05-01\" ...\n $ admissions_total   : int  1583 1580 1779 1821 1689 1871 1784 1623 1673 1780 ...\n $ admissions_white   : int  600 615 706 730 704 758 760 659 673 734 ...\n $ admissions_black   : int  193 189 235 260 215 223 206 177 236 205 ...\n $ admissions_hispanic: num  633 640 701 669 618 738 670 629 636 696 ...\n $ admissions_amerind : num  130 114 115 125 129 121 119 123 102 110 ...\n $ admissions_asian   : num  6 3 4 8 0 5 6 8 8 10 ...\n $ admissions_other   : num  21 19 18 29 23 26 23 27 18 25 ...\n $ releases_total     : int  1649 1559 1693 1659 1570 1718 1637 1665 1653 1616 ...\n $ releases_white     : int  653 644 703 685 651 673 661 659 673 648 ...\n $ releases_black     : int  194 169 206 193 174 224 221 198 188 202 ...\n $ releases_hispanic  : num  688 610 657 616 603 662 626 653 641 630 ...\n $ releases_amerind   : num  85 111 93 136 111 132 107 120 123 108 ...\n $ releases_asian     : num  7 6 5 3 7 5 4 9 4 5 ...\n $ releases_other     : num  22 19 29 26 24 22 18 26 24 23 ...\n $ state              : chr  \"Arizona\" \"Arizona\" \"Arizona\" \"Arizona\" ...\n\n\n\n\nNext, we read the CSV file admissions_releases_states.csv into a dataframe df.\n\n\nWe applied str() to display the structure of the dataset, including the names and types of the columns.\n\ndf$date = as.Date(df$date, format=\"%Y-%m-%d\")\n\n\n\nWe converted the date column from a string format to a proper Date format using as.Date().\n\n\nThis allows for easier date-based operations in the future.\n\ndata = df %&gt;%\n  rename(\n    Date = date,\n    Total_Admissions = admissions_total,\n    White_Admissions = admissions_white,\n    Black_Admissions = admissions_black,\n    Hispanic_Admissions = admissions_hispanic,\n    AmericanIndian_Admissions = admissions_amerind,\n    Asian_Admissions = admissions_asian,\n    Other_Admissions = admissions_other,\n    Total_Releases = releases_total,\n    White_Releases = releases_white,\n    Black_Releases = releases_black,\n    Hispanic_Releases = releases_hispanic,\n    AmericanIndian_Releases = releases_amerind,\n    Asian_Releases = releases_asian,\n    Other_Releases = releases_other,\n    State = state\n  )\n\n\n\nWe applied rename() to change the column names to more representative and understandable terms, making the data clearer to work with.\n\nsapply(data, function(x) sum(is.na(x)))\n\n                     Date          Total_Admissions          White_Admissions \n                        0                         0                         0 \n         Black_Admissions       Hispanic_Admissions AmericanIndian_Admissions \n                        0                         0                         0 \n         Asian_Admissions          Other_Admissions            Total_Releases \n                        0                         0                         0 \n           White_Releases            Black_Releases         Hispanic_Releases \n                        0                         0                         0 \n  AmericanIndian_Releases            Asian_Releases            Other_Releases \n                        0                         0                         0 \n                    State \n                        0 \n\n\n\n\nWe applied sapply() to check for any missing values in the dataset. This function returns the number of NA (missing) values for each column.\n\ndata = data %&gt;% distinct()\n\n\n\nWe removed any duplicate rows in the dataset by applying the distinct() function, ensuring each row in data is unique.\n\nsummary(data)\n\n      Date            Total_Admissions White_Admissions Black_Admissions\n Min.   :2000-01-01   Min.   :   1.0   Min.   :   1.0   Min.   :   0.0  \n 1st Qu.:2015-07-01   1st Qu.: 318.5   1st Qu.: 217.0   1st Qu.:  36.0  \n Median :2018-02-01   Median : 617.0   Median : 368.5   Median : 109.0  \n Mean   :2017-02-26   Mean   : 823.2   Mean   : 452.2   Mean   : 192.4  \n 3rd Qu.:2020-05-01   3rd Qu.: 861.0   3rd Qu.: 458.0   3rd Qu.: 264.0  \n Max.   :2022-09-01   Max.   :6872.0   Max.   :2707.0   Max.   :1918.0  \n Hispanic_Admissions AmericanIndian_Admissions Asian_Admissions\n Min.   :   0.0      Min.   :  0.00            Min.   : 0.000  \n 1st Qu.:   0.0      1st Qu.:  1.00            1st Qu.: 0.000  \n Median :  26.0      Median : 13.00            Median : 3.000  \n Mean   : 144.7      Mean   : 19.31            Mean   : 3.864  \n 3rd Qu.:  96.0      3rd Qu.: 29.00            3rd Qu.: 6.000  \n Max.   :2208.0      Max.   :159.00            Max.   :40.000  \n Other_Admissions  Total_Releases   White_Releases   Black_Releases  \n Min.   :  0.000   Min.   :  44.0   Min.   :  36.0   Min.   :   0.0  \n 1st Qu.:  0.000   1st Qu.: 353.0   1st Qu.: 248.0   1st Qu.:  37.0  \n Median :  2.000   Median : 654.0   Median : 387.0   Median : 121.0  \n Mean   :  9.732   Mean   : 878.7   Mean   : 469.9   Mean   : 212.8  \n 3rd Qu.: 13.000   3rd Qu.: 898.8   3rd Qu.: 481.0   3rd Qu.: 269.0  \n Max.   :217.000   Max.   :7522.0   Max.   :2420.0   Max.   :1816.0  \n Hispanic_Releases AmericanIndian_Releases Asian_Releases   Other_Releases   \n Min.   :   0.0    Min.   :  0.00          Min.   : 0.000   Min.   :   0.00  \n 1st Qu.:   0.0    1st Qu.:  1.00          1st Qu.: 0.000   1st Qu.:   0.00  \n Median :  28.0    Median : 13.00          Median : 3.000   Median :   2.00  \n Mean   : 160.9    Mean   : 19.41          Mean   : 3.939   Mean   :  11.79  \n 3rd Qu.: 106.0    3rd Qu.: 30.00          3rd Qu.: 6.000   3rd Qu.:  13.00  \n Max.   :3319.0    Max.   :149.00          Max.   :34.000   Max.   :1911.00  \n    State          \n Length:1914       \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n\nFinally, we did a statistical summary of the cleaned dataset using the summary() function, which provides basic statistics like the minimum, maximum, and mean values for numerical columns.\n\nsaveRDS(data, \"dataset/cleaned_dataset.rds\")\n\n\n\nWe saved the cleaned dataset as an .rds file using saveRDS().\n\n\nThis will allow for quick loading of the cleaned dataset in future sessions using read_rds().\n\nadmissions_totals = data %&gt;%\n  summarise(\n    Total_White_Admissions = sum(White_Admissions, na.rm = TRUE),\n    Total_Black_Admissions = sum(Black_Admissions, na.rm = TRUE),\n    Total_Hispanic_Admissions = sum(Hispanic_Admissions, na.rm = TRUE),\n    Total_AmericanIndian_Admissions = sum(AmericanIndian_Admissions, na.rm = TRUE),\n    Total_Asian_Admissions = sum(Asian_Admissions, na.rm = TRUE),\n    Total_Other_Admissions = sum(Other_Admissions, na.rm = TRUE)\n  )\n\nreleases_totals = data %&gt;%\n  summarise(\n    Total_White_Releases = sum(White_Releases, na.rm = TRUE),\n    Total_Black_Releases = sum(Black_Releases, na.rm = TRUE),\n    Total_Hispanic_Releases = sum(Hispanic_Releases, na.rm = TRUE),\n    Total_AmericanIndian_Releases = sum(AmericanIndian_Releases, na.rm = TRUE),\n    Total_Asian_Releases = sum(Asian_Releases, na.rm = TRUE),\n    Total_Other_Releases = sum(Other_Releases, na.rm = TRUE)\n  )\n\n\n\nHere, we calculated the total admissions and releases for each racial group by summing the values across the entire dataset. This ensures we can visualize the total counts of admissions and releases for different racial groups over the entire time range.\n\nadmissions_melt = tidyr::gather(admissions_totals, key = \"Race\", value = \"Admissions\")\nreleases_melt = tidyr::gather(releases_totals, key = \"Race\", value = \"Releases\")\n\n\nadmissions_melt$Race = c(\"White\", \"Black\", \"Hispanic\", \"American Indian\", \"Asian\", \"Other\")\nreleases_melt$Race = c(\"White\", \"Black\", \"Hispanic\", \"American Indian\", \"Asian\", \"Other\")\n\n\n\nHere, we reshaped the summarized data using tidyr::gather() to convert it into a long format, which is suitable for plotting with ggplot2. Additionally, we ensured the race names were labeled correctly for clear and consistent x-axis labels in the plots.\n\nggplot(admissions_melt, aes(x = reorder(Race, -Admissions), y = Admissions, fill = Race)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Total Prison Admissions by Race for the Entire Time Range\", x = \"Race\", y = \"Total Admissions\") +\n  theme_minimal() +\n  theme(\n    axis.title.x = element_text(margin = margin(t = 10)), \n    axis.title.y = element_text(margin = margin(r = 10))\n  ) +\n  scale_fill_manual(values = c(\n    \"White\" = \"#1f77b4\",    \n    \"Black\" = \"#ff7f0e\",    \n    \"Hispanic\" = \"#2ca02c\", \n    \"American Indian\" = \"#d62728\", \n    \"Asian\" = \"#9467bd\",    \n    \"Other\" = \"#8c564b\"   \n  ))\n\n\n\n\n\n\n\n\n\n\nIn this plot, we visualized the total prison admissions by race across the entire time range from January 1, 2000 to September 1, 2022. Each bar represents a different racial group, and we used custom colors for the bars to distinguish them. The bars are sorted in descending order based on the total admissions for each race. The bar plot for total prison admissions by race shows that White individuals account for the highest number of admissions (865,467), followed by Black individuals (368,346), and Hispanic individuals (277,007). American Indian admissions (36,958) are notably lower, and Asian (7,396) and Other (18,627) groups represent the smallest proportions. These disparities highlight racial differences in prison admissions, and future analyses will explore how these patterns change over time, particularly focusing on significant periods such as the COVID-19 pandemic.\n\nggplot(releases_melt, aes(x = reorder(Race, -Releases), y = Releases, fill = Race)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Total Prison Releases by Race for the Entire Time Range\", x = \"Race\", y = \"Total Releases\") +\n  theme_minimal() +\n  theme(\n    axis.title.x = element_text(margin = margin(t = 10)), \n    axis.title.y = element_text(margin = margin(r = 10))\n  ) +\n  scale_fill_manual(values = c(\n    \"White\" = \"#1f77b4\",  \n    \"Black\" = \"#ff7f0e\",  \n    \"Hispanic\" = \"#2ca02c\", \n    \"American Indian\" = \"#d62728\",\n    \"Asian\" = \"#9467bd\",  \n    \"Other\" = \"#8c564b\" \n  ))\n\n\n\n\n\n\n\n\n\n\nSimilarly, this plot shows the total prison releases by race for the entire time range from January 1, 2000 to September 1, 2022. Like the admissions plot, the bars are color-coded and sorted in descending order of total releases, giving a clear overview of the distribution of releases among different racial groups. The bar plot for total prison releases shows similar trends, with White individuals having the highest release count (899298), followed by Black (407339) and Hispanic (307995) individuals. Again, American Indian (37153), Asian (7540), and Other (22,563) groups have smaller totals. Moving forward, we will conduct a time-dependent analysis to examine trends over various time periods, with special attention to the effects of COVID-19 on prison admissions and releases during the pandemic.\n\n\nTransparency and representation are key principles in equitable data practices, both of which are relevant to our analysis of the prison admissions and releases dataset. We will ensure transparency by clearly documenting the data source, collection methods, and any potential limitations, such as missing data or sample bias, to prevent misuse or misinterpretation. Additionally, we will focus on representation by checking the distribution of different racial groups in the dataset to ensure no group is underrepresented, and we will acknowledge any imbalances that may affect our results. This approach helps promote fairness and accuracy in our analysis."
  },
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post. You’ll want to render your post to see what it will look like on the site.\n\nEvery time you want to make a new post, you can repeat step 2 above.\nWhen you want to publish your progress, follow steps 4-7 from Customize your site.\n\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html",
    "href": "posts/2023-12-20-examples/examples.html",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "href": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "MA [46]15 Final Project: Group 10",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team Group 10. The members of this team are below.\nHakob Janesian - https://github.com/HakobJanesian\nMinjun Kim - https://github.com/minjunk3\nZhuolei Chen - https://github.com/Alex030214\nShiyu Zhang - https://github.com/IvannnnZ\nDana Vivar - https://github.com/danavivar\n\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.Rmd.\nThink of this page as your 538/Upshot style article. This means that you should try to tell a story through the data and your analysis. Read articles from those sites and similar sites to get a feeling for what they are like. Try to write in the style of a news or popular article. Importantly, this page should be geared towards the general public. You shouldn’t assume the reader understands how to interpret a linear regression or a complicated plot. Focus on interpretation and visualizations."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nInteractive component\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions?\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  }
]